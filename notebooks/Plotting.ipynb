{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9a4b5a",
   "metadata": {},
   "source": [
    "# Simple Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = \"../../your_sweep_path/default\"\n",
    "\n",
    "PLOT_ALL_SEEDS = False\n",
    "# Full sweep\n",
    "MODELS_TO_PLOT = [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"Qwen/Qwen-1_8B\", \"Qwen/Qwen-7B\", \"Qwen/Qwen-14B\"]\n",
    "# Minimal sweep\n",
    "# MODELS_TO_PLOT = [\"gpt2\", \"gpt2-medium\", \"gpt2-large\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5caa051",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for result_filename in glob.glob(os.path.join(RESULTS_PATH, \"**/results_summary.json\"), recursive=True):\n",
    "    config_file = os.path.join(\"/\".join(result_filename.split(\"/\")[:-1]), \"config.json\")\n",
    "    config = json.load(open(config_file, \"r\"))\n",
    "    if config[\"model_size\"] not in MODELS_TO_PLOT:\n",
    "        continue\n",
    "    if 'seed' not in config:\n",
    "        config['seed'] = 0\n",
    "    record = config.copy()\n",
    "    if 'weak_model' in config:\n",
    "        for k in record['weak_model']:\n",
    "            if k == 'model_size':\n",
    "                assert record['weak_model'][k] == record['weak_model_size']\n",
    "            record['weak_' + k] = record['weak_model'][k]\n",
    "        del record['weak_model']\n",
    "    record.update(json.load(open(result_filename)))\n",
    "    records.append(record)\n",
    "\n",
    "df = pd.DataFrame.from_records(records).sort_values(['ds_name', 'model_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f628577",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = df.ds_name.unique()\n",
    "for dataset in datasets:\n",
    "    cur_df = df[(df.ds_name == dataset)].copy()\n",
    "    base_accuracies = cur_df[cur_df['weak_model_size'].isna()].groupby('model_size').agg({'accuracy': 'mean', 'seed': 'count'}).sort_values('accuracy')\n",
    "    base_accuracy_lookup = base_accuracies['accuracy'].to_dict()\n",
    "    base_accuracies = base_accuracies.reset_index()\n",
    "\n",
    "    cur_df['strong_model_accuracy'] = cur_df['model_size'].apply(lambda x: base_accuracy_lookup[x])\n",
    "    cur_df.loc[~cur_df['weak_model_size'].isna(), 'weak_model_accuracy'] = cur_df.loc[~cur_df['weak_model_size'].isna(), 'weak_model_size'].apply(lambda x: base_accuracy_lookup[x])\n",
    "\n",
    "    # Exclude cases where the weak model is better than the strong model from PGR calculation.\n",
    "    valid_pgr_index = (\n",
    "        (~cur_df['weak_model_size'].isna()) & \n",
    "        (cur_df['weak_model_size'] != cur_df['model_size']) & \n",
    "        (cur_df['strong_model_accuracy'] > cur_df['weak_model_accuracy'])\n",
    "    )\n",
    "    cur_df.loc[valid_pgr_index, 'pgr'] = (cur_df.loc[valid_pgr_index, 'accuracy'] - cur_df.loc[valid_pgr_index, 'weak_model_accuracy']) / (cur_df.loc[valid_pgr_index, 'strong_model_accuracy'] - cur_df.loc[valid_pgr_index, 'weak_model_accuracy'])\n",
    "\n",
    "    cur_df.loc[cur_df['weak_model_size'].isna(), \"weak_model_size\"] = \"ground truth\"\n",
    "\n",
    "    for seed in [None] + (sorted(cur_df['seed'].unique().tolist()) if PLOT_ALL_SEEDS else []):\n",
    "        plot_df = cur_df.copy().sort_values(['strong_model_accuracy']).sort_values(['loss'], ascending=False)\n",
    "        if seed is not None:\n",
    "            plot_df = plot_df[plot_df['seed'] == seed]\n",
    "\n",
    "        print(f\"Dataset: {dataset} (seed: {seed})\")\n",
    "\n",
    "        pgr_results = plot_df[~plot_df['pgr'].isna()].groupby(['loss']).aggregate({\"pgr\": \"median\"})\n",
    "\n",
    "        palette = sns.color_palette('colorblind', n_colors=len(plot_df['weak_model_size'].unique()) - 1)\n",
    "        color_dict = {model: (\"black\" if model == 'ground truth' else palette.pop()) for model in plot_df['weak_model_size'].unique()}\n",
    "\n",
    "        sns.lineplot(data=plot_df, x='strong_model_accuracy', y='accuracy', hue='weak_model_size', style='loss', markers=True, palette=color_dict)\n",
    "        pd.plotting.table(plt.gca(), pgr_results.round(4), loc='lower right', colWidths=[0.1, 0.1], cellLoc='center', rowLoc='center')\n",
    "        plt.xticks(ticks=base_accuracies['accuracy'], labels=[f\"{e} ({base_accuracy_lookup[e]:.4f})\" for e in base_accuracies['model_size']], rotation=90)\n",
    "        plt.title(f\"Dataset: {dataset} (seed: {seed})\")\n",
    "        plt.legend(loc='upper left')\n",
    "        suffix = \"\"\n",
    "        if seed is not None:\n",
    "            suffix = f\"_{seed}\"\n",
    "        plt.savefig(f\"{dataset.replace('/', '-')}{suffix}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553e612",
   "metadata": {},
   "source": [
    "# Calibration w.r.t. the soft labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e412426f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), (0,), ())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "import numpy as np\n",
    "\n",
    "w2s_path = \"../results/conf_disagree/bs=32-dn=sciq_with_supp-lp=0-l=kl-l=2e-05-ls=cosi_anne-mc=512-ms=Qwen1.5-0.5B-ntd=500-ntd=4300-ntd=4300-o=adam-s=0-see=15-twd=0-we=2-wlf=0.5-wms=opt-350m\"\n",
    "eval_results_paths = [p for p in os.listdir(w2s_path) if p.startswith(\"eval_results\") and p[-1].isdigit()]\n",
    "eval_results_paths.sort(key=lambda x: int(x.split(\"_\")[-1]))\n",
    "\n",
    "# TODO: exclude datapoints where the strong model gets it wrong even when finetuned on gt\n",
    "# TODO: alternatively compare side-by-side with gt finetuning\n",
    "\n",
    "weak_soft_labels = None\n",
    "gt_labels = None\n",
    "pred_probs = []\n",
    "for p in eval_results_paths:\n",
    "    eval_results = load_from_disk(os.path.join(w2s_path, p)).with_format(\"numpy\")\n",
    "    if weak_soft_labels is None:\n",
    "        weak_soft_labels = eval_results['weak_soft_label'][:, 1]  # type: ignore\n",
    "    else:\n",
    "        assert np.all(weak_soft_labels == eval_results['weak_soft_label'][:, 1])  # type: ignore\n",
    "    if gt_labels is None:\n",
    "        gt_labels = eval_results['soft_label'][:, 1]  # type: ignore\n",
    "    else:\n",
    "        assert np.all(gt_labels == eval_results['soft_label'][:, 1])  # type: ignore\n",
    "    pred_probs.append(eval_results['soft_pred'][:, 1])  # type: ignore\n",
    "\n",
    "weak_soft_labels = np.array(weak_soft_labels)\n",
    "pred_probs = np.array(pred_probs)\n",
    "gt_labels = np.array(gt_labels)\n",
    "weak_soft_labels.shape, pred_probs.shape, gt_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf36650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "n_time_steps = len(pred_probs)\n",
    "# Create base figure\n",
    "fig = go.Figure(\n",
    "    data=[go.Scatter(x=pred_probs[0], y=weak_soft_labels, mode='markers',  \n",
    "                     marker=dict(color=gt_labels, colorscale='Viridis', colorbar=dict(title='GT Label')))],\n",
    "    layout=go.Layout(\n",
    "        title=\"Soft Labels Over Time\",\n",
    "        xaxis=dict(range=[0, 1], title=\"Strong student predicted probability\"),\n",
    "        yaxis=dict(range=[0, 1], title=\"Weak supervisor soft label\"),\n",
    "        updatemenus=[dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[dict(label=\"Play\",\n",
    "                          method=\"animate\",\n",
    "                          args=[None, {\"frame\": {\"duration\": 700, \"redraw\": True}, \"fromcurrent\": True}]),\n",
    "                    dict(label=\"Pause\",\n",
    "                         method=\"animate\",\n",
    "                         args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}])\n",
    "                    ])]\n",
    "    ),\n",
    "    frames=[go.Frame(data=[go.Scatter(x=pred_probs[i], y=weak_soft_labels, mode='markers',\n",
    "                                        marker=dict(color=gt_labels, colorscale='Viridis', colorbar=dict(title='GT Label')))],\n",
    "                         name=str(i))\n",
    "            for i in range(1, n_time_steps)]\n",
    ")\n",
    "\n",
    "# Add axis titles\n",
    "fig.update_layout(xaxis_title=\"Strong student predicted probability\", yaxis_title=\"Weak supervisor soft label\", height=800, width=900)\n",
    "\n",
    "\n",
    "# Show animation\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
