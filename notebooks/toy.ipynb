{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LinearNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_in):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = torch.nn.Linear(d_in, 1, bias=True)\n",
    "        self.linear.weight.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.nn.functional import sigmoid\n",
    "\n",
    "OVERALL_SCALE = 1.0\n",
    "\n",
    "def get_random_feat(d, salience=1.0, orthogonal_to=None):\n",
    "    feat = torch.randn(d)\n",
    "    if orthogonal_to is not None:\n",
    "        assert orthogonal_to.ndim == 2\n",
    "        assert orthogonal_to.shape[1] == feat.shape[0], (orthogonal_to.shape, feat.shape)\n",
    "        proj = feat @ orthogonal_to.T\n",
    "        feat = feat - proj @ orthogonal_to\n",
    "    return feat / feat.norm() * salience * OVERALL_SCALE\n",
    "\n",
    "def generate_data(\n",
    "    n=1000,\n",
    "    n_trusted=100,\n",
    "    d_in=100,\n",
    "    gt_salience = 1.0,\n",
    "    proxy_saliences = (1.0,),\n",
    "    proxy_accuracies = (0.75,),\n",
    "    noise = 0.0,\n",
    "):\n",
    "    \"\"\"    \n",
    "    Returns:\n",
    "    X: torch.Tensor of shape (n, d_in) that is a sum of a ground truth feature, \n",
    "        proxy features whose errors are independent of each other, and noise\n",
    "    y: torch.Tensor of shape (n, len(proxy_accuracies)) that has a proxy label for each proxy\n",
    "    \"\"\"\n",
    "    assert len(proxy_saliences) == len(proxy_accuracies) > 0\n",
    "    \n",
    "    gt = torch.randint(0, 2, (n, 1)).float()\n",
    "    gt_feat = get_random_feat(d_in, gt_salience)\n",
    "    gt_feats = gt_feat.expand(n, -1) * (gt * 2 - 1)\n",
    "    \n",
    "    proxies = [\n",
    "        (gt.squeeze(-1) == (torch.rand(n) < acc)).float()  # TODO: maybe turn into soft labels\n",
    "        for acc in proxy_accuracies\n",
    "    ]\n",
    "    per_proxy_feat = [get_random_feat(d_in, salience) for salience in proxy_saliences]\n",
    "    proxy_feats = [\n",
    "        feat.expand(n, -1) * (proxy * 2 - 1)[:, None]\n",
    "        for feat, proxy in zip(per_proxy_feat, proxies)\n",
    "    ]\n",
    "    X = (sum(proxy_feats) + gt_feats) + torch.randn(n, d_in) * noise * OVERALL_SCALE\n",
    "    proxies = torch.stack(proxies).T\n",
    "\n",
    "    # define trusted set\n",
    "    # note that this may be unrealistic because there's little structure to\n",
    "    # the distribution shift from trusted to untrusted\n",
    "    y_trusted = torch.randint(0, 2, (n_trusted, 1)).float()\n",
    "    trusted_feat = gt_feat + sum(per_proxy_feat)\n",
    "    X_trusted = trusted_feat.expand(n_trusted, -1) * (y_trusted * 2 - 1)\n",
    "\n",
    "    return X, proxies, gt, X_trusted, y_trusted, gt_feat, per_proxy_feat\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    X_trusted=None, y_trusted=None,\n",
    "    n_epochs=1,\n",
    "    lr=1.0,\n",
    "    batch_size=64,\n",
    "    device='cuda',\n",
    "):\n",
    "    model = LinearNet(X_train.shape[1]).to(device)\n",
    "    assert X_train.shape[0] % batch_size == 0\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    n_train = X_train.shape[0]\n",
    "    n_steps = n_train * n_epochs // batch_size\n",
    "    n_test = X_test.shape[0]\n",
    "    model_n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    # It seems that one of the conditions for this to provably work is that the gradients\n",
    "    # only depend on the sign of the model's error. So we use absolute error loss here.\n",
    "    loss_fn = lambda y_pred, y: (sigmoid(y_pred) - y).abs().mean()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    all_test_preds = torch.full((n_steps * batch_size, n_test), torch.nan, device=device)\n",
    "    all_jvps = torch.full((n_steps * batch_size, n_test), torch.nan, device=device)\n",
    "    all_steps = torch.full((n_steps * batch_size,), torch.nan, device=device)\n",
    "    if X_trusted is not None and y_trusted is not None:\n",
    "        X_trusted = X_trusted.to(device)\n",
    "        y_trusted = y_trusted.to(device)\n",
    "        n_trusted = X_trusted.shape[0]\n",
    "        synthetic_preds = {k: torch.full((n_steps * n_trusted, n_test), torch.nan, device=device) for k in [\"trusted\", \"synthetic\"]}\n",
    "        synthetic_jvps = {k: torch.full((n_steps * n_trusted, n_test), torch.nan, device=device) for k in [\"trusted\", \"synthetic\"]}\n",
    "        synthetic_steps = {k: torch.full((n_steps * n_trusted,), torch.nan, device=device) for k in [\"trusted\", \"synthetic\"]}\n",
    "    else:\n",
    "        synthetic_preds = synthetic_jvps = synthetic_steps = None\n",
    "        \n",
    "    step = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in tqdm(range(0, X_train.shape[0], batch_size), desc=f'Epoch {epoch + 1}/{n_epochs}', total=n_train // batch_size):\n",
    "            test_jacobians, test_preds = get_jacobians(model, X_test)\n",
    "\n",
    "            if X_trusted is not None and y_trusted is not None:\n",
    "                for k in [\"trusted\", \"synthetic\"]:\n",
    "                    optimizer.zero_grad()\n",
    "                    y_batch = y_trusted if k == \"trusted\" else 1 - y_trusted\n",
    "                    cumul_grads = torch.full((n_trusted, model_n_params), torch.nan, device=device)\n",
    "                    for j in range(n_trusted):\n",
    "                        y_pred = model(X_trusted[j:j+1])\n",
    "                        loss = loss_fn(y_pred, y_batch[j:j+1, 0].unsqueeze(-1)) / batch_size\n",
    "                        loss.backward()\n",
    "\n",
    "                        cumul_grads[j] = torch.cat([p.grad.flatten() for p in model.parameters() if p.grad is not None])\n",
    "                    \n",
    "                    grads = cumul_grads.diff(dim=0, prepend=torch.zeros(1, model_n_params, device=device))\n",
    "                    # take signed gradient  TODO\n",
    "                    # grads = grads.sign()\n",
    "                    current_lr = optimizer.param_groups[0]['lr']\n",
    "                    update = -current_lr * grads\n",
    "                    jvp = update # TODO  @ test_jacobians.T\n",
    "\n",
    "                    start, stop = step * n_trusted, (step + 1) * n_trusted\n",
    "                    synthetic_preds[k][start:stop, :] = test_preds  # type: ignore\n",
    "                    synthetic_jvps[k][start:stop, :] = jvp  # type: ignore\n",
    "                    synthetic_steps[k][start:stop] = step  # type: ignore\n",
    "                    \n",
    "            optimizer.zero_grad()\n",
    "            cumul_grads = torch.full((batch_size, model_n_params), torch.nan, device=device)\n",
    "            for j in range(i, min(i + batch_size, n_train)):\n",
    "                X_batch = X_train[j:j+1]\n",
    "                y_batch = y_train[j:j+1] \n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch[:, 0].unsqueeze(-1)) / batch_size  # train on proxy 0\n",
    "                loss.backward()\n",
    "\n",
    "                cumul_grads[j - i] = torch.cat([p.grad.flatten() for p in model.parameters() if p.grad is not None])\n",
    "            \n",
    "            grads = cumul_grads.diff(dim=0, prepend=torch.zeros(1, model_n_params, device=device))\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            update = -current_lr * grads\n",
    "            jvp = update # TODO @ test_jacobians.T\n",
    "\n",
    "            all_test_preds[i:i+batch_size, :] = test_preds\n",
    "            all_jvps[i:i+batch_size, :] = jvp\n",
    "            all_steps[i:i+batch_size] = step\n",
    "            \n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "\n",
    "    \n",
    "    return model, all_test_preds, all_jvps, all_steps, synthetic_preds, synthetic_jvps, synthetic_steps\n",
    "\n",
    "def get_jacobians(model, X_test):\n",
    "    \"\"\"\n",
    "    Returns the Jacobian of the model's (logodds) output with respect to its parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    model_n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    jacobians = torch.full((X_test.shape[0], model_n_params), torch.nan, device=X_test.device)\n",
    "    preds = torch.full((X_test.shape[0],), torch.nan, device=X_test.device)\n",
    "    for i, x in enumerate(X_test):\n",
    "        y = model(x.unsqueeze(0))\n",
    "        y.backward()\n",
    "        jacobian = torch.cat([p.grad.flatten() for p in model.parameters() if p.grad is not None])\n",
    "        jacobians[i] = jacobian\n",
    "        preds[i] = y\n",
    "        model.zero_grad()\n",
    "    return jacobians, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concept_erasure import LeaceEraser\n",
    "from typing import Literal\n",
    "import numpy as np\n",
    "\n",
    "def erase_labels(x, soft_labels, label_erasure: Literal[\"none\", \"leace\", \"mean-diff\", \"keep-negative\", \"keep-positive\"] = \"none\"):\n",
    "    mask = np.full_like(soft_labels, True, dtype=bool)\n",
    "    if label_erasure == \"leace\":\n",
    "        eraser = LeaceEraser.fit(x=torch.from_numpy(x), z=torch.from_numpy(soft_labels))\n",
    "        erased = eraser(x=torch.tensor(x)).numpy()\n",
    "    elif label_erasure == \"mean-diff\":\n",
    "        pos_mean = np.mean(x * soft_labels[:, None], axis=0)\n",
    "        neg_mean = np.mean(x * (1 - soft_labels)[:, None], axis=0)\n",
    "        mean_diff = pos_mean - neg_mean\n",
    "        mean_diff = mean_diff / np.linalg.norm(mean_diff)\n",
    "        erased = x - x @ mean_diff[:, None] * mean_diff[None, :] / (mean_diff @ mean_diff)\n",
    "    elif label_erasure == \"keep-negative\":\n",
    "        mask = soft_labels < 0.5\n",
    "        erased = x[mask]\n",
    "    elif label_erasure == \"keep-positive\":\n",
    "        mask = soft_labels > 0.5\n",
    "        erased = x[mask]\n",
    "    elif label_erasure == \"none\":\n",
    "        erased = x\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown label erasure method {label_erasure}\")\n",
    "    return erased, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "proxy_settings = [\n",
    "    ((1.0,), (0.75,)),\n",
    "    ((1.0, 1.0), (0.75, 0.75)),\n",
    "    ((1.0, 1.0), (0.75, 0.55)),\n",
    "    ((1.0, 1.0), (0.55, 0.55)),\n",
    "    ((1.0, 1.0), (0.55, 0.75)),\n",
    "    ((1.0, 1.0), (0.75, 0.9)),\n",
    "    ((1.0, 1.0), (0.9, 0.9)),\n",
    "    ((1.0, 1.0), (0.99, 0.9)),\n",
    "    ((1.0, 0.5), (0.75, 0.9)),\n",
    "    ((1.0, 2.0), (0.55, 0.75)),\n",
    "    ((1.0, 2.0), (0.55, 0.25)),\n",
    "    ((1.0, 2.0), (0.99, 0.25)),\n",
    "    ((1.0, 2.0), (0.99, 0.75)),\n",
    "    ((1.0, 2.0), (0.75, 0.5)),\n",
    "    ((1.0, 2.0), (0.75, 0.75)),\n",
    "    ((1.0, 2.0, 1.0), (0.75, 0.25, 0.5)),\n",
    "    ((1.0, 2.0, 1.0), (0.75, 0.5, 0.9)),\n",
    "    ((1.0, 1.0, 1.0), (0.75, 0.65, 0.5)),\n",
    "    ((1.0, 1.0, 1.0), (0.75, 0.5, 0.5)),\n",
    "    ((1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 0.5), (0.75, 0.25, 0.5, 0.9, 0.75, 0.25, 0.5)),\n",
    "][::-1]\n",
    "num_seeds = 10\n",
    "results = []\n",
    "for proxy_saliences, proxy_accuracies in tqdm(proxy_settings, desc='Proxy settings', total=len(proxy_settings)):\n",
    "    print(f\"Proxy saliences: {proxy_saliences}, proxy accuracies: {proxy_accuracies}\")\n",
    "    for seed in range(num_seeds):\n",
    "        print(f\"Seed {seed}\")\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        X, y, gt, X_trusted, y_trusted, gt_feat, per_proxy_feat = generate_data(\n",
    "            n=512 + 512,\n",
    "            d_in=511,\n",
    "            gt_salience=1.0,\n",
    "            proxy_saliences=proxy_saliences,\n",
    "            proxy_accuracies=proxy_accuracies,\n",
    "            noise=0.0,\n",
    "        )\n",
    "        n_train = 512\n",
    "        batch_size = 512\n",
    "        X_train, X_test = X[:n_train], X[n_train:]\n",
    "        y_train, y_test = y[:n_train], y[n_train:]\n",
    "        gt_train, gt_test = gt[:n_train], gt[n_train:]\n",
    "\n",
    "        model, all_test_preds, all_jvps, all_steps, synthetic_preds, synthetic_jvps, synthetic_steps = train_model(X_train, X_test, y_train, y_test, X_trusted=X_trusted, y_trusted=y_trusted, n_epochs=1, lr=1., batch_size=batch_size)\n",
    "        all_test_preds, all_jvps, all_steps = all_test_preds.detach().cpu().numpy(), all_jvps.detach().cpu().numpy(), all_steps.detach().cpu().numpy()\n",
    "\n",
    "        ceil_model, ceil_all_test_preds, ceil_all_jvps, ceil_all_steps, _, _, _ = train_model(X_train, X_test, gt_train, gt_test, n_epochs=1, lr=1., batch_size=batch_size)\n",
    "        ceil_all_test_preds, ceil_all_jvps, ceil_all_steps = ceil_all_test_preds.detach().cpu().numpy(), ceil_all_jvps.detach().cpu().numpy(), ceil_all_steps.detach().cpu().numpy()\n",
    "\n",
    "        X_train, X_test, y_train, y_test, gt_train, gt_test = X_train.cpu().numpy(), X_test.cpu().numpy(), y_train.cpu().numpy(), y_test.cpu().numpy(), gt_train.cpu().numpy(), gt_test.cpu().numpy()\n",
    "        X_trusted, y_trusted = X_trusted.cpu().numpy(), y_trusted.cpu().numpy()\n",
    "        assert synthetic_preds is not None and synthetic_jvps is not None and synthetic_steps is not None\n",
    "        for k in [\"trusted\", \"synthetic\"]:\n",
    "            synthetic_preds[k] = synthetic_preds[k].detach().cpu().numpy()\n",
    "            synthetic_jvps[k] = synthetic_jvps[k].detach().cpu().numpy()\n",
    "            synthetic_steps[k] = synthetic_steps[k].detach().cpu().numpy()\n",
    "\n",
    "        # summary stats\n",
    "        aucs = [roc_auc_score(y_test[:, 0], test_preds) for test_preds in all_test_preds]\n",
    "\n",
    "        metric = \"acc\"\n",
    "        metric_fn = {\n",
    "            \"auc\": lambda y_true, y_pred: roc_auc_score(y_true, y_pred),\n",
    "            \"acc\": lambda y_true, y_pred: accuracy_score(y_true, y_pred > 0),\n",
    "        }[metric]\n",
    "        weak_floor = metric_fn(gt_test[:, 0], y_test[:, 0])\n",
    "        strong_ceil = metric_fn(gt_test[:, 0], ceil_all_test_preds[-1])\n",
    "        w2s_auroc = metric_fn(gt_test[:, 0], all_test_preds[-1])\n",
    "        w2s_auroc_against_weak = metric_fn(y_test[:, 0], all_test_preds[-1])\n",
    "        pgr = (w2s_auroc - weak_floor) / (strong_ceil - weak_floor)\n",
    "        print(f\"Weak floor {metric}: {weak_floor:.3f}\")\n",
    "        print(f\"Strong ceiling {metric}: {strong_ceil:.3f}\")\n",
    "        print(f\"W2S {metric} (against weak): {w2s_auroc_against_weak:.3f}\")\n",
    "        print(f\"W2S {metric}: {w2s_auroc:.3f} (PGR={pgr:.3f})\")\n",
    "\n",
    "        erasure = \"none\"\n",
    "        weak_label_erased, _ = erase_labels(all_jvps, y_train[:, 0], label_erasure=erasure)\n",
    "\n",
    "        synth_erased = {k: erase_labels(synthetic_jvps[k], y_trusted[:, 0].repeat(n_train // batch_size, axis=0), label_erasure=erasure)[0] for k in [\"trusted\", \"synthetic\"]}  # type: ignore\n",
    "        diff = synth_erased[\"trusted\"].mean(0) - synth_erased[\"synthetic\"].mean(0)\n",
    "        diff /= np.linalg.norm(diff)\n",
    "        proj_diff = weak_label_erased @ diff\n",
    "\n",
    "        # we claim to be able to distinguish cases where all of our measurements are correct\n",
    "        # from cases where our first proxy is incorrect \n",
    "        # (we don't care about cases where other proxies are incorrect but the first one is correct since we can discard them anyways)\n",
    "        all_agree_or_gt_disagrees = (y_train.std(axis=-1) == 0) | (gt_train[:, 0] != y_train[:, 0])\n",
    "        print(f\"Keeping {100 * all_agree_or_gt_disagrees.mean():.1f}% of examples for measuring tampering AUC\")\n",
    "        is_y0_correct = (gt_train[:, 0] == y_train[:, 0])[all_agree_or_gt_disagrees]\n",
    "        try:\n",
    "            meas_tamp_auc = roc_auc_score(is_y0_correct, proj_diff[all_agree_or_gt_disagrees])\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            meas_tamp_auc = np.nan\n",
    "            print(\"All examples were\", is_y0_correct.mean())\n",
    "        print(f\"Meas. tampering AUC: {meas_tamp_auc:.3f}\")\n",
    "        results.append({\n",
    "            \"proxy_saliences\": proxy_saliences,\n",
    "            \"proxy_accuracies\": proxy_accuracies,\n",
    "            \"seed\": seed,\n",
    "            \"weak_floor\": weak_floor,\n",
    "            \"strong_ceil\": strong_ceil,\n",
    "            \"w2s_auroc\": w2s_auroc,\n",
    "            \"w2s_auroc_against_weak\": w2s_auroc_against_weak,\n",
    "            \"pgr\": pgr,\n",
    "            \"meas_tamp_auc\": meas_tamp_auc,\n",
    "        })\n",
    "        if meas_tamp_auc < 0.9999999:\n",
    "            print(\"Meas. tampering AUC < 1\")\n",
    "            print(results[-1])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gt_dir = gt_test[:, 0] - 0.5\n",
    "weak_dir = y_test[:, 0] - 0.5\n",
    "err_dir = weak_dir - gt_dir\n",
    "min_step, max_step = 0, 2  # all_steps.max()\n",
    "step_mask = (all_steps >= min_step) & (all_steps < max_step)\n",
    "proj_weak = (weak_label_erased @ weak_dir)[step_mask]\n",
    "# proj_weak = (weak_label_erased @ err_dir)[step_mask]\n",
    "# proj_weak = (weak_label_erased @ diff)[step_mask]\n",
    "proj_gt = (weak_label_erased @ gt_dir)[step_mask]\n",
    "plt.scatter(proj_weak, proj_gt, c=(y_train[:, 0] - gt_train[:, 0])[step_mask], cmap=\"viridis\", alpha=0.5)\n",
    "xmin, xmax = proj_weak.min(), proj_weak.max()\n",
    "plt.plot([xmin, xmax], [xmin, xmax], color=\"black\", linestyle=\"--\")\n",
    "plt.plot([xmin, xmax], [-xmin, -xmax], color=\"black\", linestyle=\"--\", label=\"y=$\\pm$x\")\n",
    "plt.xlabel(\"Projection onto weak generalization\")\n",
    "plt.ylabel(\"Projection onto ground truth generalization\")\n",
    "plt.legend()\n",
    "plt.colorbar()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
